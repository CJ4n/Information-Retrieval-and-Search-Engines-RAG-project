{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5hH-WBI1R2H"
      },
      "source": [
        "# H02C8b Information Retrieval and Search Engines: RAG Project\n",
        "\n",
        "Welcome to the notebook companion for the IRSE project. You will find all starter code here. You are encouraged to use this code, as it has been confirmed to work for the RAG pipeline described in the assignment handout. However, you are certainly welcome to make any changes you see fit, provided that your code is written in Python and runs without issue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Kkz_9Y7FrLe"
      },
      "source": [
        "**IMPORTANT**: Do not submit a notebook as your final solution. It will not be graded. Refer to assignment handout for more information about the submission format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw2_H111Frbu"
      },
      "source": [
        "**IMPORTANT**: Be mindful of your runtime usage, if working in Colab. At the beginning of every session, navigate to the top menu bar in Colab and select **Runtime > Change runtime type > CPU (Python 3)**. This will ensure that your session runs on CPU and that you do not waste any GPU allocation for the day. GPUs are provided by Google on a limited daily basis, and access is given every 24 hours. It is best that you complete the TF-IDF/search component before loading models and running inference on the GPU runtime.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM9AFxoyfQZT"
      },
      "source": [
        "If you have any questions, feel free to email [Thomas](mailto:thomas.bauwens@kuleuven.be) or [Kushal](mailto:kushaljayesh.tatariya@kuleuven.be)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpcHebZfGi-f"
      },
      "source": [
        "## RAG for recipe recommendation:\n",
        "\n",
        "We will begin by installing the huggingface `datasets` library for easily loading our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy3FsTE2bKfU"
      },
      "outputs": [],
      "source": [
        "# ! pip -q install datasets\n",
        "# !wget https://people.cs.kuleuven.be/~thomas.bauwens/irse_documents_2025_recipes.parquet\n",
        "# !wget https://people.cs.kuleuven.be/~thomas.bauwens/irse_queries_2025_recipes.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "uIq7VwBoFvV1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/yan/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /home/yan/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/yan/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /home/yan/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /home/yan/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /home/yan/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/yan/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from multiprocessing import Pool, cpu_count\n",
        "from functools import partial\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "import datasets\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tqdm import tqdm\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "tqdm.pandas()\n",
        "import time\n",
        "import nltk\n",
        "from utils import *\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"wordnet\")\n",
        "DEBUG=False\n",
        "# from google.colab import userdata\n",
        "# userdata.get(\"HF_TOKEN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_average_precision(relevant_doc_ids, retrieved_doc_ids):\n",
        "    hit_count = 0\n",
        "    sum_precisions = 0.0\n",
        "    for i, doc_id in enumerate(retrieved_doc_ids):\n",
        "        if doc_id in relevant_doc_ids:\n",
        "            hit_count += 1\n",
        "            precision_at_i = hit_count / (i + 1)\n",
        "            sum_precisions += precision_at_i\n",
        "\n",
        "    if len(relevant_doc_ids) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return sum_precisions / len(relevant_doc_ids)\n",
        "\n",
        "\n",
        "def calculate_mean_average_precision(all_relevant_doc_ids, all_retrieved_doc_ids):\n",
        "    average_precisions = []\n",
        "    for relevant, retrieved in zip(all_relevant_doc_ids, all_retrieved_doc_ids):\n",
        "        ap = calculate_average_precision(relevant, retrieved)\n",
        "        average_precisions.append(ap)\n",
        "\n",
        "    return {\n",
        "        \"map\": (\n",
        "            sum(average_precisions) / len(average_precisions)\n",
        "            if average_precisions\n",
        "            else 0.0\n",
        "        )\n",
        "    }\n",
        "\n",
        "\n",
        "def calculate_precision_recall_f1_optimized(relevant_doc_ids, retrieved_doc_ids):\n",
        "    relevant_set = set(relevant_doc_ids)\n",
        "    retrieved_set = set(retrieved_doc_ids)\n",
        "    true_positives = len(relevant_set.intersection(retrieved_set))\n",
        "\n",
        "    if len(retrieved_set) == 0:\n",
        "        precision = 0.0\n",
        "        recall = 0.0 if len(relevant_set) > 0 else 1.0\n",
        "        f1 = 0.0\n",
        "    elif len(relevant_set) == 0:\n",
        "        precision = 0.0\n",
        "        recall = 0.0\n",
        "        f1 = 0.0\n",
        "    else:\n",
        "        precision = true_positives / len(retrieved_set)\n",
        "        recall = true_positives / len(relevant_set)\n",
        "        if precision + recall > 0:\n",
        "            f1 = 2 * precision * recall / (precision + recall)\n",
        "        else:\n",
        "            f1 = 0.0\n",
        "\n",
        "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "\n",
        "def calculate_macro_averages(metrics_per_query):\n",
        "    precision_values = [metrics[\"precision\"] for metrics in metrics_per_query]\n",
        "    recall_values = [metrics[\"recall\"] for metrics in metrics_per_query]\n",
        "    f1_values = [metrics[\"f1\"] for metrics in metrics_per_query]\n",
        "\n",
        "    macro_precision = np.mean(precision_values)\n",
        "    macro_recall = np.mean(recall_values)\n",
        "    macro_f1 = np.mean(f1_values)\n",
        "\n",
        "    return {\n",
        "        \"macro_precision\": macro_precision,\n",
        "        \"macro_recall\": macro_recall,\n",
        "        \"macro_f1\": macro_f1,\n",
        "    }\n",
        "\n",
        "\n",
        "def calculate_micro_averages_optimized(all_relevant_doc_ids, all_retrieved_doc_ids):\n",
        "    all_relevant = [\n",
        "        doc_id for query_relevant in all_relevant_doc_ids for doc_id in query_relevant\n",
        "    ]\n",
        "    all_retrieved = [\n",
        "        doc_id\n",
        "        for query_retrieved in all_retrieved_doc_ids\n",
        "        for doc_id in query_retrieved\n",
        "    ]\n",
        "\n",
        "    relevant_set = set(all_relevant)\n",
        "    retrieved_set = set(all_retrieved)\n",
        "    true_positives = len(relevant_set.intersection(retrieved_set))\n",
        "\n",
        "    if len(retrieved_set) == 0:\n",
        "        micro_precision = 0.0\n",
        "        micro_recall = 0.0 if len(relevant_set) > 0 else 1.0\n",
        "        micro_f1 = 0.0\n",
        "    elif len(relevant_set) == 0:\n",
        "        micro_precision = 0.0\n",
        "        micro_recall = 1.0\n",
        "        micro_f1 = 0.0\n",
        "    else:\n",
        "        micro_precision = true_positives / len(retrieved_set)\n",
        "        micro_recall = true_positives / len(relevant_set)\n",
        "        if micro_precision + micro_recall > 0:\n",
        "            micro_f1 = (\n",
        "                2 * micro_precision * micro_recall / (micro_precision + micro_recall)\n",
        "            )\n",
        "        else:\n",
        "            micro_f1 = 0.0\n",
        "\n",
        "    return {\n",
        "        \"micro_precision\": micro_precision,\n",
        "        \"micro_recall\": micro_recall,\n",
        "        \"micro_f1\": micro_f1,\n",
        "    }\n",
        "\n",
        "\n",
        "def evaluate_combination(combo, queries, recipes, recipe_ids, k_values, thresholds):\n",
        "    i, j = combo\n",
        "    k = k_values[i]\n",
        "    threshold = thresholds[j]\n",
        "\n",
        "    metrics = evaluate_ir_system(\n",
        "        queries, recipes, recipe_ids, k=int(k), threshold=threshold\n",
        "    )\n",
        "\n",
        "    return (i, j, metrics[\"macro_f1\"])\n",
        "\n",
        "\n",
        "def create_parameter_heatmap(queries, recipes, recipe_ids):\n",
        "    thresholds = np.arange(0.1, 0.30, 0.05)\n",
        "    k_values = np.arange(20, 60, 5)\n",
        "    total_combinations = len(k_values) * len(thresholds)\n",
        "    f1_matrix = np.zeros((len(k_values), len(thresholds)))\n",
        "\n",
        "    combinations = [\n",
        "        (i, j) for i in range(len(k_values)) for j in range(len(thresholds))\n",
        "    ]\n",
        "\n",
        "    evaluate_func = partial(\n",
        "        evaluate_combination,\n",
        "        queries=queries,\n",
        "        recipes=recipes,\n",
        "        recipe_ids=recipe_ids,\n",
        "        k_values=k_values,\n",
        "        thresholds=thresholds,\n",
        "    )\n",
        "\n",
        "    num_processes = min(cpu_count(), total_combinations)\n",
        "    print(f\"Running parameter search using {num_processes} processes...\")\n",
        "    with Pool(processes=num_processes) as pool:\n",
        "        results = list(\n",
        "            tqdm(\n",
        "                pool.imap(evaluate_func, combinations),\n",
        "                total=total_combinations,\n",
        "                desc=\"Evaluating combinations\",\n",
        "            )\n",
        "        )\n",
        "\n",
        "    for i, j, f1_score in results:\n",
        "        f1_matrix[i, j] = f1_score\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(\n",
        "        f1_matrix,\n",
        "        annot=True,\n",
        "        fmt=\".3f\",\n",
        "        cmap=\"YlGnBu\",\n",
        "        xticklabels=[f\"{t:.2f}\" for t in thresholds],\n",
        "        yticklabels=[f\"{int(k)}\" for k in k_values],\n",
        "    )\n",
        "\n",
        "    plt.title(\"Macro F1 Scores for Combinations of k and Threshold\")\n",
        "    plt.xlabel(\"Threshold\")\n",
        "    plt.ylabel(\"k\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"ir_parameter_heatmap{int(time.time())}.png\", dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # Find the best combination\n",
        "    best_i, best_j = np.unravel_index(f1_matrix.argmax(), f1_matrix.shape)\n",
        "    best_k = k_values[best_i]\n",
        "    best_threshold = thresholds[best_j]\n",
        "    best_f1 = f1_matrix[best_i, best_j]\n",
        "\n",
        "    print(f\"\\nBest parameter combination:\")\n",
        "    print(f\"k = {int(best_k)}, threshold = {best_threshold:.2f}\")\n",
        "    print(f\"Macro F1 = {best_f1:.4f}\")\n",
        "\n",
        "    return {\n",
        "        \"f1_matrix\": f1_matrix,\n",
        "        \"best_k\": int(best_k),\n",
        "        \"best_threshold\": best_threshold,\n",
        "        \"best_f1\": best_f1,\n",
        "    }\n",
        "\n",
        "\n",
        "def retrieve_documents(query_text, recipies, recipe_ids, k, threshold):\n",
        "    if len(recipies) != len(recipe_ids):\n",
        "        raise ValueError(\"Recipes and recipe_ids must have the same length\")\n",
        "    if k is None and threshold is None:\n",
        "        raise ValueError(\"Either k or threshold must be specified\")\n",
        "    \n",
        "    query = preprocess_text(query_text)\n",
        "    if DEBUG:\n",
        "        print(\"PREPROCEDDE QUERY: \", query)\n",
        "    q_uni = vec_uni.transform([query])\n",
        "    q_bi = vec_bi.transform([query])\n",
        "    q_all = hstack([q_uni, q_bi])\n",
        "\n",
        "    X_all = hstack([X_uni, X_bi])\n",
        "    if DEBUG:\n",
        "        uni_feature_names = vec_uni.get_feature_names_out()\n",
        "        bi_feature_names = vec_bi.get_feature_names_out()\n",
        "\n",
        "        q_uni_indices = q_uni.nonzero()[1]\n",
        "        q_bi_indices = q_bi.nonzero()[1]\n",
        "\n",
        "        print(\"Query terms (unigrams):\", [uni_feature_names[i] for i in q_uni_indices])\n",
        "        print(\"Query terms (bigrams):\", [bi_feature_names[i] for i in q_bi_indices])\n",
        "\n",
        "    cosine_similarities = cosine_similarity(q_all, X_all).flatten()\n",
        "    euclidean_dis = euclidean_distances(q_all, X_all).flatten()\n",
        "\n",
        "    # results = [\n",
        "    #     (recipies[i], recipe_ids[i], 1 / (1+euclidean_dis[i]))\n",
        "    #     for i in range(len(recipies))\n",
        "    # ]\n",
        "\n",
        "    results = [\n",
        "        (recipies[i], recipe_ids[i], cosine_similarities[i])\n",
        "        for i in range(len(recipies))\n",
        "    ]\n",
        "    results.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    if threshold is not None:\n",
        "        results = [r for r in results if r[2] >= threshold]\n",
        "\n",
        "    if k is not None:\n",
        "        results = results[:k]\n",
        "    return results\n",
        "\n",
        "\n",
        "def evaluate_ir_system(queries, recipies, recipe_ids, k, threshold):\n",
        "    metrics_per_query = []\n",
        "    all_relevant_doc_ids = []\n",
        "    all_retrieved_doc_ids = []\n",
        "\n",
        "    for _, row in tqdm(queries.iterrows()):\n",
        "        query_text = row[\"q\"]\n",
        "        relevant_doc_ids = [doc[0] for doc in row[\"r\"]]\n",
        "\n",
        "        results = retrieve_documents(query_text, recipies, recipe_ids, k, threshold)\n",
        "        retrieved_doc_ids = [result[1] for result in results]\n",
        "        # TODO: understand how its calcualted\n",
        "        query_metrics = calculate_precision_recall_f1_optimized(\n",
        "            relevant_doc_ids, retrieved_doc_ids\n",
        "        )\n",
        "        metrics_per_query.append(query_metrics)\n",
        "\n",
        "        all_relevant_doc_ids.append(relevant_doc_ids)\n",
        "        all_retrieved_doc_ids.append(retrieved_doc_ids)\n",
        "    # TODO: understand how its calcualted\n",
        "\n",
        "    macro_metrics = calculate_macro_averages(metrics_per_query)\n",
        "    micro_metrics = calculate_micro_averages_optimized(\n",
        "        all_relevant_doc_ids, all_retrieved_doc_ids\n",
        "    )\n",
        "    MAP_metric = calculate_mean_average_precision(\n",
        "        all_relevant_doc_ids, all_retrieved_doc_ids\n",
        "    )\n",
        "\n",
        "    all_metrics = {**macro_metrics, **micro_metrics, **MAP_metric}\n",
        "    return all_metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08BidyMMGSpB"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.load_dataset(\n",
        "    \"parquet\", data_files=\"./irse_documents_2025_recipes.parquet\"\n",
        ")[\"train\"]\n",
        "queries_data = json.load(open(\"./irse_queries_2025_recipes.json\", \"r\"))\n",
        "\n",
        "df = dataset.to_pandas()\n",
        "\n",
        "recipies = df.apply(\n",
        "    lambda row: f\"{row['name']} {row['description']} {row['ingredients']} {row['steps']}\",\n",
        "    axis=1,\n",
        ")\n",
        "\n",
        "recipe_ids = dataset[\"official_id\"]\n",
        "print(\"Number of documents:\", len(recipies))\n",
        "\n",
        "queries = pd.DataFrame(columns=[\"q\", \"r\", \"a\"])\n",
        "for query_item in queries_data[\"queries\"]:\n",
        "    query_text = query_item[\"q\"]\n",
        "    relevance_pairs = query_item[\"r\"]\n",
        "    answer = query_item[\"a\"]\n",
        "    queries = pd.concat(\n",
        "        [\n",
        "            queries,\n",
        "            pd.DataFrame({\"q\": [query_text], \"r\": [relevance_pairs], \"a\": [answer]}),\n",
        "        ],\n",
        "        ignore_index=True,\n",
        "    )\n",
        "\n",
        "print(\"Number of queries:\", len(queries))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "# remove words which are meaningless in context of cooking\n",
        "stop_words.update(\n",
        "    [\n",
        "        \"add\",\n",
        "        \"added\",\n",
        "        \"adding\",\n",
        "        \"addition\",\n",
        "        \"also\",\n",
        "        \"almost\",\n",
        "        \"another\",\n",
        "        \"easily\",\n",
        "        \"easy\",\n",
        "    ]\n",
        ")\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "def preprocess_text(doc):\n",
        "    doc = doc.translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n",
        "\n",
        "    words = word_tokenize(doc)\n",
        "\n",
        "    words = [\n",
        "        lemmatizer.lemmatize(word)\n",
        "        for word in words\n",
        "        if word not in stop_words and word.isalpha()\n",
        "    ]\n",
        "\n",
        "    return \" \".join(words)\n",
        "\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "filename = \"preprocessed_recipes6.pkl\"\n",
        "if os.path.exists(filename):\n",
        "    with open(filename, \"rb\") as f:\n",
        "        preprocessed_recipes = pickle.load(f)\n",
        "else:\n",
        "    preprocessed_recipes = [preprocess_text(doc) for doc in tqdm(recipies)]\n",
        "    with open(filename, \"wb\") as f:\n",
        "        pickle.dump(preprocessed_recipes, f)  # Adjust based on the format used\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vec_uni = TfidfVectorizer(min_df=20, max_df=0.5, ngram_range=(1, 1))\n",
        "vec_bi = TfidfVectorizer(\n",
        "    min_df=50,\n",
        "    max_df=0.4,\n",
        "    ngram_range=(2, 2),\n",
        "    max_features=10000,\n",
        ")\n",
        "\n",
        "X_uni = vec_uni.fit_transform(preprocessed_recipes)\n",
        "X_bi = vec_bi.fit_transform(preprocessed_recipes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab_uni = vec_uni.get_feature_names_out()\n",
        "idf_values_uni = vec_uni.idf_\n",
        "\n",
        "sorted_terms_uni = sorted(\n",
        "    list(zip(vocab_uni, idf_values_uni)), key=lambda x: x[1], reverse=True\n",
        ")\n",
        "\n",
        "sorted_terms_uni"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab_bi = vec_bi.get_feature_names_out()\n",
        "idf_values_bi = vec_bi.idf_\n",
        "\n",
        "sorted_terms_bi = sorted(\n",
        "    list(zip(vocab_bi, idf_values_bi)), key=lambda x: x[1], reverse=True\n",
        ")\n",
        "sorted_terms_bi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import *\n",
        "\n",
        "# chosen using grid search over hyper params space\n",
        "best_K = 40\n",
        "best_threshold = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# retrieve_documents(query_text=\"\",recipies=recipies, recipe_ids=recipe_ids, k=best_K, threshold=best_threshold)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = evaluate_ir_system(\n",
        "    queries, recipies, recipe_ids, k=best_K, threshold=best_threshold\n",
        ")\n",
        "\n",
        "metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "DEBUG=True\n",
        "\n",
        "def print_query(q):\n",
        "    results = retrieve_documents(\n",
        "    q, recipies, recipe_ids, k=best_K, threshold=best_threshold\n",
        ")\n",
        "    print(f\"Query: {q}\\n\")\n",
        "    for recipe, recipe_id, score in results:\n",
        "        print(f\"Recipe ID: {recipe_id}, Score: {score:.4f}\")\n",
        "        recipe_info = df[df[\"official_id\"] == recipe_id].iloc[0]\n",
        "        print(f\"Name: {recipe_info['name']}\")\n",
        "        print(f\"Description: {recipe_info['description']}\")\n",
        "        print(f\"Ingredients: {recipe_info['ingredients']}\")\n",
        "        print(f\"Steps: {recipe_info['steps']}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_queries = [\n",
        "   \"Where can I follow cooking classes\",  # should not return anything, but retursn -> it's very hard to cut off noisy data using thresholds, as sometimes irrelvant documents have hihger score, then relevant ones for different queries -> \n",
        "    \"How does Gordon Ramsay make his beef Wellington?\", # found things wiht gordron ramsey or beef wellington, but nothing with noth -> ignores context\n",
        "\n",
        "    \"Do you know any soups from Paraguay?\", # \"Paragya\" appears in only two documents, so it's extremally rare, since I require term to appear in more then 20 documents, it does not appear in TF_IDF so it's ignored -> TF-IDF ignores very rare terms\n",
        "    \"How do you make piza\", # does not handle types -> problem with 'synonyms'\n",
        "    \"I do not want to eat pizza, what can I eat instead?\", # -> did not capture negation\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PREPROCEDDE QUERY:  make piza\n",
            "Query terms (unigrams): ['make']\n",
            "Query terms (bigrams): []\n",
            "Query: How do you make piza\n",
            "\n",
            "Recipe ID: 134171, Score: 0.2344\n",
            "Name: mexican coleslaw sans mayo\n",
            "Description: tomatoes and oregano make it italian; wine and tarragon make it french. sour cream makes it russian; lemon and cinnamon make it greek. soy sauce makes it chinese; garlic makes it good.-alice may brock of alices restaurant fame. \n",
            "\n",
            "albiet no garlic in this recipe, but this is a refreshing alternative to mayonnaise-based coleslaw in a taco or on the side. to make ahead: cover and refrigerate for up to 1 day. toss again to refresh just before serving. (eating well, june/july 2003)\n",
            "Ingredients: cilantro, rice vinegar, extra virgin olive oil, salt, coleslaw\n",
            "Steps: place cabbage and carrots in a colander, rinse well with cold water to crisp, let drain for 5 minute, meanwhile , whisk cilantro , vinegar , oil , and salt in a large bowl, add cabbage and carrots, toss well to coat\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_query(test_queries[3]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMH0BuyxkVrb"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "\n",
        "# Recipe Assistant\n",
        "\n",
        "## Context\n",
        "You are a helpful recipe assistant with access to a database of recipes. The system has already retrieved the most relevant recipes to the user's query using TF-IDF similarity. Your goal is to provide helpful, accurate responses about recipes, cooking techniques, ingredient substitutions, and culinary advice based on the retrieved recipes.\n",
        "\n",
        "## Retrieved Recipes\n",
        "The following recipes have been retrieved as most relevant to the user's query:\n",
        "\n",
        "{retrieved_recipes}\n",
        "\n",
        "## Instructions\n",
        "1. **Answer directly from the retrieved recipes when possible.** Use the information from the provided recipes to answer questions about ingredients, cooking methods, nutritional information, and preparation steps.\n",
        "\n",
        "2. **For ingredient questions:**\n",
        "   - Provide accurate amounts and measurements from the recipes\n",
        "   - Suggest possible substitutions based on common culinary knowledge\n",
        "   - Explain the purpose of key ingredients in the dish\n",
        "\n",
        "3. **For cooking technique questions:**\n",
        "   - Explain preparation methods mentioned in the recipes\n",
        "   - Clarify cooking times and temperatures\n",
        "   - Describe expected results and how to tell when food is properly cooked\n",
        "\n",
        "4. **For modification requests:**\n",
        "   - Suggest appropriate adjustments for dietary restrictions (vegan, gluten-free, etc.)\n",
        "   - Explain how to scale recipes up or down\n",
        "   - Offer ideas for flavor variations while maintaining the core identity of the dish\n",
        "\n",
        "5. **For general questions:**\n",
        "   - Provide brief culinary background/history when relevant\n",
        "   - Explain unfamiliar cooking terms\n",
        "   - Suggest pairings, serving suggestions, and storage recommendations\n",
        "\n",
        "## Response Format\n",
        "- Start with a direct answer to the user's question\n",
        "- Keep your responses concise but comprehensive\n",
        "- For multi-step instructions or complex concepts, organize information in a clear, logical structure\n",
        "- If the retrieved recipes don't contain sufficient information to answer the query, acknowledge the limitations and provide general culinary knowledge that might help\n",
        "- When suggesting modifications not explicitly in the retrieved recipes, clearly indicate these are your recommendations based on culinary principles\n",
        "\n",
        "## Limitations\n",
        "- Don't make claims about specific nutritional values unless they're mentioned in the retrieved recipes\n",
        "- If asked about topics completely unrelated to cooking or the recipes provided, politely redirect the conversation back to recipe-related topics\n",
        "- Don't invent or fabricate details about recipes that aren't in the retrieved data\n",
        "\n",
        "## User Query\n",
        "{user_query}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCxrQbNjXJze"
      },
      "outputs": [],
      "source": [
        "irrelevant_context = \"\"\"\n",
        "Richard Gary Brautigan (January 30, 1935 – c. September 16, 1984)\n",
        "was an American novelist, poet, and short story writer. A prolific writer,\n",
        "he wrote throughout his life and published ten novels, two collections of\n",
        "short stories, and four books of poetry. Brautigan's work has been published\n",
        "both in the United States and internationally throughout Europe, Japan,\n",
        "and China. He is best known for his novels Trout Fishing in America (1967),\n",
        "In Watermelon Sugar (1968), and The Abortion: An Historical Romance 1966 (1971).\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf67P4TgVvd1"
      },
      "source": [
        "**IMPORTANT**: only run the following code when you have implemented a working retrieval system. When you are ready to work with language models, navigate to the menu bar in Colab and select **Runtime > Change runtime type > T4 GPU**. If you find yourself working on not GPU-intenstive tasks in this notebook, change your runtime back to CPU to preserve access.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPBnqJFRbS2G"
      },
      "outputs": [],
      "source": [
        "# ! pip -q install git+https://github.com/huggingface/transformers\n",
        "# ! pip -q install datasets bitsandbytes accelerate xformers einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9QXH6gVbtuC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers\n",
        "import numpy as np\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "# from google.colab import userdata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W59_uVOuIPJ6"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(token=\"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\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyMVZEHXYbRz"
      },
      "source": [
        "The code below will load a Mistral 7B instruct model and quantize it via `bitesandbytes`. Doing so will ensure that the model will not take up too much memory and make inference more efficient. Note that the call to `AutoModelForCausalLM.from_pretrained()` will take a while, as the model's weights must be downloaded from the huggingface hub. Also note that you are not restricted to using Mistral, and are welcome to experiment with other models (though you will have more luck with chat and instruction-tuned variants)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEuL6xNM-TD2"
      },
      "outputs": [],
      "source": [
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "bnb_config = transformers.BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTeEJDcr-ZSL"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id, trust_remote_code=True, quantization_config=bnb_config, device_map=\"cpu\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEJJsLzQdK9q"
      },
      "source": [
        "A tokenizer is required in order to convert strings into integer sequences that can be passed as input to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxgIwhXU-gyS"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-2ofJeBdgJF"
      },
      "outputs": [],
      "source": [
        "retrieved_recipes = \"1. Chocolate Chip Cookies...\\n2. Brownie Bites...\"\n",
        "user_query = \"Can I use coconut oil instead of butter in cookies?\"\n",
        "\n",
        "# Fill in the template\n",
        "input_string_with_context = prompt.format(\n",
        "    retrieved_recipes=retrieved_recipes, user_query=user_query\n",
        ")\n",
        "\n",
        "input_string_without_context = prompt.format(\n",
        "    retrieved_recipes=irrelevant_context, user_query=user_query\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtQNQGwj-nbM"
      },
      "outputs": [],
      "source": [
        "encoded_prompt = tokenizer(\n",
        "    input_string_with_context, return_tensors=\"pt\", add_special_tokens=False\n",
        ")\n",
        "encoded_prompt = encoded_prompt.to(\"cpu\")\n",
        "generated_ids = model.generate(**encoded_prompt, max_new_tokens=1000, do_sample=True)\n",
        "decoded = tokenizer.batch_decode(generated_ids)\n",
        "print(decoded[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfjgBnG--te6"
      },
      "outputs": [],
      "source": [
        "encoded_prompt = tokenizer(\n",
        "    input_string_without_context, return_tensors=\"pt\", add_special_tokens=False\n",
        ")\n",
        "encoded_prompt = encoded_prompt.to(\"cuda\")\n",
        "generated_ids = model.generate(**encoded_prompt, max_new_tokens=1000, do_sample=True)\n",
        "decoded = tokenizer.batch_decode(generated_ids)\n",
        "print(decoded[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTKh_sKlLjBp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
